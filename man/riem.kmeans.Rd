% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/clustering_kmeans.R
\name{riem.kmeans}
\alias{riem.kmeans}
\title{K-Means Clustering}
\usage{
riem.kmeans(
  riemobj,
  k = 2,
  geometry = c("intrinsic", "extrinsic"),
  maxiter = 10,
  nstart = 5,
  algorithm = c("MacQueen", "Lloyd"),
  init = c("plus", "random")
)
}
\arguments{
\item{riemobj}{a S3 \code{"riemdata"} class for \eqn{N} manifold-valued data.}

\item{k}{the number of clusters.}

\item{geometry}{(case-insensitive) name of geometry; either geodesic (\code{"intrinsic"}) or embedded (\code{"extrinsic"}) geometry.}

\item{maxiter}{the maximum number of iterations allowed.}

\item{nstart}{the number of random starts.}

\item{algorithm}{(case-insensitive) name of an algorithm to be run. (default: \code{"MacQueen"})}

\item{init}{(case-insensitive) name of an initialization scheme. (default: \code{"plus"})}
}
\value{
a named list containing\describe{
\item{means}{a 3d array where each slice along 3rd dimension is a matrix representation of class mean.}
\item{cluster}{a length-\eqn{N} vector of class labels (from \eqn{1:k}).}
\item{score}{within-cluster sum of squares (WCSS).}
}
}
\description{
Given \eqn{N} observations  \eqn{X_1, X_2, \ldots, X_N \in \mathcal{M}}, 
perform k-means clustering by minimizing within-cluster sum of squares (WCSS). 
Since the problem is NP-hard and sensitive to the initialization, we provide an 
option with multiple starts and return the best result with respect to WCSS.
}
\examples{
#-------------------------------------------------------------------
#          Example on Sphere : a dataset with three types
#
# class 1 : 10 perturbed data points near (1,0,0) on S^2 in R^3
# class 2 : 10 perturbed data points near (0,1,0) on S^2 in R^3
# class 3 : 10 perturbed data points near (0,0,1) on S^2 in R^3
#-------------------------------------------------------------------
## GENERATE DATA
mydata = list()
for (i in 1:10){
  tgt = c(1, stats::rnorm(2, sd=0.1))
  mydata[[i]] = tgt/sqrt(sum(tgt^2))
}
for (i in 11:20){
  tgt = c(rnorm(1,sd=0.1),1,rnorm(1,sd=0.1))
  mydata[[i]] = tgt/sqrt(sum(tgt^2))
}
for (i in 21:30){
  tgt = c(stats::rnorm(2, sd=0.1), 1)
  mydata[[i]] = tgt/sqrt(sum(tgt^2))
}
myriem = wrap.sphere(mydata)
mylabs = rep(c(1,2,3), each=10)

## K-MEDOIDS WITH K=2,3,4
clust2 = riem.kmeans(myriem, k=2)
clust3 = riem.kmeans(myriem, k=3)
clust4 = riem.kmeans(myriem, k=4)

## MDS FOR VISUALIZATION
mds2d = riem.mds(myriem, ndim=2)$embed

## VISUALIZE
opar <- par(no.readonly=TRUE)
par(mfrow=c(2,2), pty="s")
plot(mds2d, pch=19, main="true label", col=mylabs)
plot(mds2d, pch=19, main="K=2", col=clust2$cluster)
plot(mds2d, pch=19, main="K=3", col=clust3$cluster)
plot(mds2d, pch=19, main="K=4", col=clust4$cluster)
par(opar)

}
\references{
\insertRef{lloyd_least_1982}{Riemann}

\insertRef{macqueen_methods_1967}{Riemann}
}
\seealso{
\code{\link{riem.kmeanspp}}
}
\concept{clustering}
